{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNR7Tp5zks4J7UczhvI/L43"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["!pip install faiss-cpu tqdm openai"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"MduS-tBA4AMH","executionInfo":{"status":"ok","timestamp":1763464402529,"user_tz":-540,"elapsed":18051,"user":{"displayName":"ìµœí˜œì£¼","userId":"10636324700644526344"}},"outputId":"9306b186-9029-4683-ca11-12841a77a015"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting faiss-cpu\n","  Downloading faiss_cpu-1.13.0-cp39-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (7.7 kB)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\n","Requirement already satisfied: openai in /usr/local/lib/python3.12/dist-packages (1.109.1)\n","Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.12/dist-packages (from faiss-cpu) (2.0.2)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from faiss-cpu) (25.0)\n","Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai) (4.11.0)\n","Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai) (1.9.0)\n","Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.28.1)\n","Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.12.0)\n","Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from openai) (2.11.10)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai) (1.3.1)\n","Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.12/dist-packages (from openai) (4.15.0)\n","Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai) (3.11)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (2025.10.5)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n","Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n","Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.2)\n","Downloading faiss_cpu-1.13.0-cp39-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (23.6 MB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m23.6/23.6 MB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: faiss-cpu\n","Successfully installed faiss-cpu-1.13.0\n"]}]},{"cell_type":"code","source":["!pip install -U langchain-community faiss-cpu"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"GwAFHCeS4iVZ","executionInfo":{"status":"ok","timestamp":1763464425754,"user_tz":-540,"elapsed":18291,"user":{"displayName":"ìµœí˜œì£¼","userId":"10636324700644526344"}},"outputId":"7c17b1ab-cb90-40b7-b157-caa52dec2aa0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting langchain-community\n","  Downloading langchain_community-0.4.1-py3-none-any.whl.metadata (3.0 kB)\n","Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.12/dist-packages (1.13.0)\n","Collecting langchain-core<2.0.0,>=1.0.1 (from langchain-community)\n","  Downloading langchain_core-1.0.5-py3-none-any.whl.metadata (3.6 kB)\n","Collecting langchain-classic<2.0.0,>=1.0.0 (from langchain-community)\n","  Downloading langchain_classic-1.0.0-py3-none-any.whl.metadata (3.9 kB)\n","Requirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.0.44)\n","Collecting requests<3.0.0,>=2.32.5 (from langchain-community)\n","  Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n","Requirement already satisfied: PyYAML<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (6.0.3)\n","Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (3.13.2)\n","Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (8.5.0)\n","Collecting dataclasses-json<0.7.0,>=0.6.7 (from langchain-community)\n","  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n","Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.12.0)\n","Requirement already satisfied: langsmith<1.0.0,>=0.1.125 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.4.42)\n","Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.4.3)\n","Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.0.2)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from faiss-cpu) (25.0)\n","Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n","Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.4.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.8.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.7.0)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.4.1)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.22.0)\n","Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7.0,>=0.6.7->langchain-community)\n","  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n","Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7.0,>=0.6.7->langchain-community)\n","  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n","Collecting langchain-text-splitters<2.0.0,>=1.0.0 (from langchain-classic<2.0.0,>=1.0.0->langchain-community)\n","  Downloading langchain_text_splitters-1.0.0-py3-none-any.whl.metadata (2.6 kB)\n","Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain-classic<2.0.0,>=1.0.0->langchain-community) (2.11.10)\n","Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.1->langchain-community) (1.33)\n","Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.1->langchain-community) (4.15.0)\n","Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (0.28.1)\n","Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (3.11.4)\n","Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (1.0.0)\n","Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (0.25.0)\n","Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (1.2.1)\n","Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (0.4.2)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (3.4.4)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (3.11)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (2025.10.5)\n","Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3.0.0,>=1.4.0->langchain-community) (3.2.4)\n","Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (4.11.0)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (1.0.9)\n","Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (0.16.0)\n","Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.0.1->langchain-community) (3.0.0)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-classic<2.0.0,>=1.0.0->langchain-community) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-classic<2.0.0,>=1.0.0->langchain-community) (2.33.2)\n","Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community)\n","  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n","Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (1.3.1)\n","Downloading langchain_community-0.4.1-py3-none-any.whl (2.5 MB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m41.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n","Downloading langchain_classic-1.0.0-py3-none-any.whl (1.0 MB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m40.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading langchain_core-1.0.5-py3-none-any.whl (471 kB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m471.5/471.5 kB\u001b[0m \u001b[31m25.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading requests-2.32.5-py3-none-any.whl (64 kB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading langchain_text_splitters-1.0.0-py3-none-any.whl (33 kB)\n","Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n","Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n","Installing collected packages: requests, mypy-extensions, marshmallow, typing-inspect, dataclasses-json, langchain-core, langchain-text-splitters, langchain-classic, langchain-community\n","  Attempting uninstall: requests\n","    Found existing installation: requests 2.32.4\n","    Uninstalling requests-2.32.4:\n","      Successfully uninstalled requests-2.32.4\n","  Attempting uninstall: langchain-core\n","    Found existing installation: langchain-core 0.3.79\n","    Uninstalling langchain-core-0.3.79:\n","      Successfully uninstalled langchain-core-0.3.79\n","  Attempting uninstall: langchain-text-splitters\n","    Found existing installation: langchain-text-splitters 0.3.11\n","    Uninstalling langchain-text-splitters-0.3.11:\n","      Successfully uninstalled langchain-text-splitters-0.3.11\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\n","langchain 0.3.27 requires langchain-core<1.0.0,>=0.3.72, but you have langchain-core 1.0.5 which is incompatible.\n","langchain 0.3.27 requires langchain-text-splitters<1.0.0,>=0.3.9, but you have langchain-text-splitters 1.0.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed dataclasses-json-0.6.7 langchain-classic-1.0.0 langchain-community-0.4.1 langchain-core-1.0.5 langchain-text-splitters-1.0.0 marshmallow-3.26.1 mypy-extensions-1.1.0 requests-2.32.5 typing-inspect-0.9.0\n"]}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qSl0UW2f45rd","executionInfo":{"status":"ok","timestamp":1763464450569,"user_tz":-540,"elapsed":21281,"user":{"displayName":"ìµœí˜œì£¼","userId":"10636324700644526344"}},"outputId":"6ab8cc70-ed92-4d44-ecf6-9b5f5ccb3007"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["from openai import OpenAI\n","from langchain_community.vectorstores import FAISS\n","from langchain.embeddings.base import Embeddings\n","from tqdm import tqdm\n","import json, time, os\n","\n","# ======================================================\n","# 1) Upstage Client ì—°ê²°\n","# ======================================================\n","client = OpenAI(\n","    api_key=\"up_m5U58N6ugmo67EJWWRnoKUcCvYFqK\",\n","    base_url=\"https://api.upstage.ai/v1\"\n",")\n","\n","# ======================================================\n","# 2) LangChain í˜¸í™˜ Embedding Wrapper\n","# ======================================================\n","class SolarEmbedding(Embeddings):\n","\n","    def embed_query(self, text: str):\n","        res = client.embeddings.create(\n","            model=\"solar-embedding-1-large-query\",   # ì¿¼ë¦¬ìš©\n","            input=text\n","        )\n","        return res.data[0].embedding\n","\n","    def embed_documents(self, texts, batch_size=8):\n","        all_embeddings = []\n","\n","        for i in tqdm(range(0, len(texts), batch_size)):\n","            batch = texts[i:i + batch_size]\n","\n","            res = client.embeddings.create(\n","                model=\"solar-embedding-1-large-passage\",\n","                input=batch\n","            )\n","            batch_embeddings = [d.embedding for d in res.data]\n","            all_embeddings.extend(batch_embeddings)\n","\n","        return all_embeddings\n","\n","# ======================================================\n","# 3) JSON â†’ Embedding â†’ FAISS\n","# --------------------------\n","def embed_json(json_path, save_dir=\"ewha_vectorstore\"):\n","    # jsonl ë˜ëŠ” json ìë™ ì²˜ë¦¬\n","    chunks = []\n","    with open(json_path, \"r\", encoding=\"utf-8\") as f:\n","        first = f.readline().strip()\n","        f.seek(0)\n","        if first.startswith(\"{\"):\n","            try:\n","                chunks = json.load(f)\n","            except:\n","                f.seek(0)\n","                chunks = [json.loads(line)[\"text\"] for line in f]\n","        else:\n","            raise ValueError(\"File format invalid.\")\n","\n","    print(f\"âœ… Loaded {len(chunks)} chunks\")\n","\n","    emb_model = SolarEmbedding()\n","\n","    # batch embedding\n","    embeddings = emb_model.embed_documents(chunks)\n","    print(\"âœ… Embedding complete!\")\n","\n","    # FAISS ì €ì¥\n","    vectorstore = FAISS.from_texts(chunks, emb_model)\n","    vectorstore.save_local(save_dir)\n","    print(f\"ğŸ‰ Saved FAISS vectorstore to {save_dir}/\")\n","\n","\n","# --------------------------\n","# 4) Run\n","# --------------------------\n","json_path = \"/content/drive/MyDrive/NLP_TermProject/chunking/ewha_chunks_by_article.jsonl\"\n","embed_json(json_path)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qqQnAX4b34oF","executionInfo":{"status":"ok","timestamp":1763464543782,"user_tz":-540,"elapsed":90116,"user":{"displayName":"ìµœí˜œì£¼","userId":"10636324700644526344"}},"outputId":"66de8da4-f2af-49ce-fe07-5b641506c5a0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["âœ… Loaded 242 chunks\n"]},{"output_type":"stream","name":"stderr","text":["100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 31/31 [00:41<00:00,  1.35s/it]\n"]},{"output_type":"stream","name":"stdout","text":["âœ… Embedding complete!\n"]},{"output_type":"stream","name":"stderr","text":["100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 31/31 [00:43<00:00,  1.41s/it]\n"]},{"output_type":"stream","name":"stdout","text":["ğŸ‰ Saved FAISS vectorstore to ewha_vectorstore/\n"]}]},{"cell_type":"code","source":["from openai import OpenAI\n","from langchain_community.vectorstores import FAISS\n","from langchain.embeddings.base import Embeddings\n","from tqdm import tqdm\n","import json, time, os\n","\n","# Upstage Client ìƒì„±\n","client = OpenAI(\n","    api_key=\"up_m5U58N6ugmo67EJWWRnoKUcCvYFqK\",\n","    base_url=\"https://api.upstage.ai/v1\"\n",")\n","\n","# LangChain í˜¸í™˜ Embedding Wrapper\n","class SolarEmbedding(Embeddings):\n","\n","    def embed_query(self, text: str):\n","        res = client.embeddings.create(\n","            model=\"solar-embedding-1-large-query\",\n","            input=text\n","        )\n","        return res.data[0].embedding\n","\n","    def embed_documents(self, texts, batch_size=8):\n","        all_embeddings = []\n","        for i in tqdm(range(0, len(texts), batch_size)):\n","            batch = texts[i:i+batch_size]\n","            res = client.embeddings.create(\n","                model=\"solar-embedding-1-large-passage\",\n","                input=batch\n","            )\n","            all_embeddings.extend([d.embedding for d in res.data])\n","        return all_embeddings\n"],"metadata":{"id":"wr4-tl0b-D03"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ì €ì¥ëœ ë²¡í„°ìŠ¤í† ì–´ ê²½ë¡œ (ì „ì²´ êµ¬ì¡° ê¸°ë°˜)\n","vectorstore_path = \"/content/ewha_vectorstore\"\n","\n","# FAISS ì¸ë±ìŠ¤ ë¡œë“œ\n","embedding_model = SolarEmbedding()\n","db = FAISS.load_local(\n","    vectorstore_path,\n","    embedding_model,\n","    allow_dangerous_deserialization=True\n",")\n","\n","retriever = db.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 3})\n","\n","print(\"âœ… Retriever ready!\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"K39g-9gL-DxT","executionInfo":{"status":"ok","timestamp":1763464564602,"user_tz":-540,"elapsed":30,"user":{"displayName":"ìµœí˜œì£¼","userId":"10636324700644526344"}},"outputId":"02f77b4a-6e04-4b3d-882a-45921f197b4f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["âœ… Retriever ready!\n"]}]},{"cell_type":"code","source":["def ask_solar(question, retrieved_docs):\n","    \"\"\"\n","    question: ì‚¬ìš©ìì˜ ì§ˆë¬¸\n","    retrieved_docs: top-k ë¬¸ë‹¨ ë¬¸ìì—´ ë¦¬ìŠ¤íŠ¸\n","    \"\"\"\n","    context = \"\\n\\n\".join([f\"- {doc}\" for doc in retrieved_docs])\n","\n","    prompt = f\"\"\"\n","ì‚¬ìš©ì ì§ˆë¬¸ì— ë‹µí•´ì£¼ì„¸ìš”. ë¬¸ë§¥ì€ ì•„ë˜ì™€ ê°™ìŠµë‹ˆë‹¤.\n","ë‹µë³€ì€ ë°˜ë“œì‹œ ìµœì¢…ì— \"[ANSWER]: (A) ...\" í˜•íƒœë¡œ íŒŒì‹± ê°€ëŠ¥í•˜ê²Œ í•´ì£¼ì„¸ìš”.\n","\n","[ì»¨í…ìŠ¤íŠ¸]\n","{context}\n","\n","[ì§ˆë¬¸]\n","{question}\n","    \"\"\"\n","\n","    response = client.chat.completions.create(\n","        model=\"solar-pro2\",\n","        messages=[{\"role\":\"user\",\"content\":prompt}],\n","        # instructionì— ë”°ë¼ reasoning=False (chat-only)\n","    )\n","\n","    return response.choices[0].message.content"],"metadata":{"id":"lxXfoUbL-Dt-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def rag_answer(query):\n","    # retrieverë¡œ ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰\n","    docs = retriever.invoke(query)\n","\n","    # ë¬¸ì„œ ë‚´ìš©ì„ í•˜ë‚˜ì˜ contextë¡œ ê²°í•©\n","    context = \"\\n\\n\".join([d.page_content for d in docs])\n","\n","    # ëª¨ë¸ í˜¸ì¶œ\n","    completion = client.chat.completions.create(\n","        model=\"solar-pro\",\n","        messages=[\n","            {\"role\": \"system\", \"content\": \"You must answer ONLY based on the context.\"},\n","            {\"role\": \"user\", \"content\": f\"Context: {context}\\n\\nQuestion: {query}\"}\n","        ]\n","    )\n","\n","    return completion.choices[0].message.content"],"metadata":{"id":"s1BXPPPj_iZa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def rag_answer(question):\n","    # 1) top-k ë¬¸ë‹¨ ê²€ìƒ‰\n","    docs = retriever.invoke(question)\n","    retrieved_texts = [d.page_content for d in docs]\n","\n","    print(\"ğŸ” Retrieved docs:\")\n","    for i, t in enumerate(retrieved_texts):\n","        print(f\"\\n--- Document #{i+1} ---\\n{t[:300]}...\\n\")\n","\n","    # 2) Solar LLM í˜¸ì¶œ\n","    answer = ask_solar(question, retrieved_texts)\n","    return answer"],"metadata":{"id":"7dOghARk-Dqd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["question = \"ì˜ì–´ ë° ì •ë³´ ìê²© ì·¨ë“ ì‹œ ì¸ì •ë˜ëŠ” í•™ì ì€ ëª‡ ì ì¸ê°€?\"\n","\n","answer = rag_answer(question)\n","print(\"\\nğŸŸ¦ ìµœì¢… RAG ë‹µë³€:\")\n","print(answer)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lDR47oJn-L1G","executionInfo":{"status":"ok","timestamp":1763464761512,"user_tz":-540,"elapsed":185606,"user":{"displayName":"ìµœí˜œì£¼","userId":"10636324700644526344"}},"outputId":"0a579638-2f69-420b-ef4d-83347c9a2b77"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["ğŸ” Retrieved docs:\n","\n","--- Document #1 ---\n","ì œ48ì¡°ì˜2(ì˜ì–´ ë° ì •ë³´ì¸ì¦) â‘  ì˜ì–´ ë° ì •ë³´ ë“±ì— ê´€í•˜ì—¬ ì¼ì •í•œ ê¸°ì¤€ì˜ ëŠ¥ë ¥ì´ë‚˜ ìê²©ì„\n","ì·¨ë“í•œ ê²½ìš° ì´ë¥¼ ê° 3í•™ì ìœ¼ë¡œ ì¸ì •í•˜ê³  ì¸ì¦ì„œë¥¼ êµë¶€í•  ìˆ˜ ìˆë‹¤. (ê°œì • 2015.9.18.)\n","â‘¡ ì œ1í•­ì˜ ì‹œí–‰ì— ê´€í•œ ì‚¬í•­ì€ ì´ì¥ì´ ë”°ë¡œ ì •í•œë‹¤.\n","[ë³¸ì¡°ì‹ ì„¤ 2000.6.20.] [ì œëª©ê°œì • 2015.9.18.] 2 - 2 - 12\n","\n","ì´í™”ì—¬ìëŒ€í•™êµ í•™ì¹™...\n","\n","\n","--- Document #2 ---\n","ì œ48ì¡°(ì¡¸ì—…ì— í•„ìš”í•œ í•™ì ) â‘  ì¡¸ì—…ì— í•„ìš”í•œ í•™ì ì€ 129í•™ì ìœ¼ë¡œ í•œë‹¤. (ê°œì • 2012.2.\n","29.)\n","â‘¡ ì œ1í•­ì˜ ê·œì •ì— ë¶ˆêµ¬í•˜ê³  ì´ì¥ì€ êµê³¼ê³¼ì •ìƒì˜ í•„ìš”ì— ë”°ë¼ íŠ¹ì • í•™ê³¼ ë˜ëŠ” ì „ê³µì˜ ì¡¸\n","ì—…ì— í•„ìš”í•œ í•™ì ì„ 129í•™ì  ì´ìƒìœ¼ë¡œ ì •í•  ìˆ˜ ìˆë‹¤. (ê°œì • 2012.2.29)\n","â‘¢ í•™ìƒì€ ì¬í•™ê¸°ê°„ì¤‘ ì œ1í•­ ë˜ëŠ” ì œ2í•­ì˜ í•™ì ì™¸ì— í›ˆë ¨í•™ì ì„ ì·¨ë“í•˜ì—¬ì•¼ í•œë‹¤.\n","â‘£ ì‚­ì œ (2000.6.20.)\n","â‘¤ í•™ìƒì€ ì¬í•™ê¸°ê°„ ì¤‘ ì œ1í•­ ë˜ëŠ” ì œ2í•­ì˜ í•™ì  ë‚´ì—ì„œ ì´ì¥ì´ ì •í•˜ëŠ” ì†Œì •ì˜ í•™ì ì„ ì˜\n","ì–´ê°•ì˜ë¡œ ì´ìˆ˜í•˜ì—¬ì•¼ í•œë‹¤. (ì‹ ì„¤ 2013.11.20)\n","â‘¥...\n","\n","\n","--- Document #3 ---\n","ì œ35ì¡°ì˜3(í•™ì ì˜ ì¸ì •) â‘  ë‹¤ìŒ ê° í˜¸ì˜ ê²½ìš°ì— ì·¨ë“í•œ í•™ì ì€ ì´ì¥ì˜ ìŠ¹ì¸ì„ ì–»ì–´ ì¡¸ì—…ì—\n","í•„ìš”í•œ í•™ì ì˜ 2ë¶„ì˜ 1ì˜ ë²”ìœ„ ì•ˆì—ì„œ ì´ë¥¼ ë³¸êµì—ì„œ ì·¨ë“í•œ ê²ƒìœ¼ë¡œ ë³¸ë‹¤. (ê°œì •\n","2012.12.31.)\n","1. ì¬í•™ ì¤‘ êµ­ë‚´ì™¸ì˜ ë‹¤ë¥¸ í•™êµì—ì„œ í•™ì ì„ ì·¨ë“í•œ ê²½ìš°\n","2. ì…í•™ ì „ êµ­ë‚´ì™¸ì˜ ê³ ë“±í•™êµì™€ ã€Œê³ ë“±êµìœ¡ë²•ã€...\n","\n","\n","ğŸŸ¦ ìµœì¢… RAG ë‹µë³€:\n","[ANSWER]: (A) ê° 3í•™ì   \n","\n","**í•´ì„¤**:  \n","ì œ48ì¡°ì˜2(ì˜ì–´ ë° ì •ë³´ì¸ì¦) â‘ í•­ì— ë”°ë¥´ë©´, ì˜ì–´ ë° ì •ë³´ ë¶„ì•¼ì—ì„œ ì¼ì • ê¸°ì¤€ ì´ìƒì˜ ëŠ¥ë ¥ ë˜ëŠ” ìê²©ì„ ì·¨ë“í•œ ê²½ìš°, **ê° 3í•™ì **ìœ¼ë¡œ ì¸ì •í•˜ê³  ì¸ì¦ì„œë¥¼ êµë¶€í•  ìˆ˜ ìˆë„ë¡ ê·œì •ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ë”°ë¼ì„œ ì˜ì–´ ìê²©ê³¼ ì •ë³´ ìê²© ê°ê° 3í•™ì ì”© ì´ 6í•™ì ì´ ì¸ì •ë  ìˆ˜ ìˆìœ¼ë‚˜, ì§ˆë¬¸ì—ì„œëŠ” \"ì˜ì–´ ë° ì •ë³´ ìê²© ì·¨ë“ ì‹œ ì¸ì •ë˜ëŠ” í•™ì \"ì„ ë‹¨ì¼ í•­ëª©ìœ¼ë¡œ ë¬»ê³  ìˆìœ¼ë¯€ë¡œ, ê° ìê²©ë³„ ê¸°ì¤€ì¸ **3í•™ì **ì´ ì •ë‹µì…ë‹ˆë‹¤.  \n","\n","(â€» í•™ì¹™ ê°œì • ì´ë ¥(2015.9.18.) ë° ë³¸ì¡° ì‹ ì„¤(2000.6.20.) ì‚¬í•­ì„ ë°˜ì˜í•¨)\n"]}]}]}